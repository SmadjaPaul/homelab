---
date: 2026-01-29
project: homelab
version: 4.0
status: current
lastUpdated: 2026-01-29
note: Architecture validated - simplified services catalog, 2-tier auth strategy, AdGuard Home, KubeVirt gaming roadmap
---

# Architecture Document: Homelab Infrastructure with Proxmox + Omni

**Purpose**: This document defines the architectural decisions, implementation patterns, and project structure for a homelab infrastructure built on Proxmox VE with Talos Linux Kubernetes clusters managed by Omni, featuring Dev/Prod environments with CI/CD pipeline.

**Key Inspirations & What We Adopt**:

| Repo | Adopted Patterns | Services/Tools |
|------|------------------|----------------|
| [qjoly/GitOps](https://github.com/qjoly/GitOps) | Omni cluster templates, Talos config | Vault, Volsync, Cloudflare Tunnels |
| [ravilushqa/homelab](https://github.com/ravilushqa/homelab) | Proxmox + Terraform patterns | Gateway API, Home Assistant, Immich |
| [mitchross/talos-argocd-proxmox](https://github.com/mitchross/talos-argocd-proxmox) | ArgoCD sync waves, GPU Operator | Longhorn, sync wave architecture |
| [Mafyuh/iac](https://github.com/Mafyuh/iac) | Security stack, automation | Twingate, Wazuh, n8n, Bitwarden, Trivy |
| [ahinko/home-ops](https://github.com/ahinko/home-ops) | Renovate config, Taskfile | Automated updates, justfile patterns |

---

## 1. Project Context

### Hardware

**Homelab Server** (Proxmox Host):
- **IP**: 192.168.68.51 (Proxmox Web UI: https://192.168.68.51:8006)
- **RAM**: 64GB
- **Storage**: 1TB SSD (system), 2x 20TB HDD (data)
- **GPU**: NVIDIA GPU (for gaming VMs)

**Oracle Cloud** (Always Free Tier):
- **Instances**: 2 ARM VMs (12GB RAM + 2 OCPUs each = 24GB total)
- **Storage**: 139GB block storage
- **Bandwidth**: 10 TB/month egress

### Target Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      OMNI (Self-Hosted on OCI)      â”‚
                    â”‚  Single pane of glass for clusters  â”‚
                    â”‚  + Keycloak SSO + Cloudflare Tunnel â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                            â”‚                            â”‚
           â–¼                            â–¼                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Proxmox (Home)    â”‚    â”‚   Proxmox (Home)    â”‚    â”‚   Oracle Cloud      â”‚
â”‚   DEV Cluster       â”‚    â”‚   PROD Cluster      â”‚    â”‚   CLOUD Cluster     â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚    â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚    â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚   â€¢ Minimal testing â”‚    â”‚   â€¢ Stable services â”‚    â”‚   â€¢ Family services â”‚
â”‚   â€¢ CI validation   â”‚    â”‚   â€¢ Gaming VMs      â”‚    â”‚   â€¢ External access â”‚
â”‚   â€¢ 2GB RAM total   â”‚    â”‚   â€¢ Local storage   â”‚    â”‚   â€¢ Omni management â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                            â”‚                            â”‚
           â”‚                            â”‚â—„â”€â”€â”€â”€Twingate/WireGuardâ”€â”€â”€â”€â–ºâ”‚
           â”‚                            â”‚      (Zero Trust VPN)      â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚   GitOps Repo   â”‚
                               â”‚   (This Repo)   â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Requirements Summary

**Environments**:
- **DEV**: Testing environment, receives CI deployments first
- **PROD**: Production environment, receives stable deployments after DEV validation
- **CLOUD**: Oracle Cloud cluster for family-shared services

**Target Users**: Developer administrator (Paul), graphic designer, family members (5 people)

---

## 2. Core Architectural Decisions

### 2.1 Hypervisor: Proxmox VE

**Decision**: Proxmox VE as the base hypervisor with Infrastructure as Code

**Rationale**:
- âœ… Web-based VM management (https://192.168.68.51:8006)
- âœ… Terraform provider for IaC (`bpg/proxmox`)
- âœ… GPU passthrough support for gaming VMs
- âœ… ZFS support for storage
- âœ… Mature, stable platform

**IaC Tools**:
- **Terraform/OpenTofu**: VM provisioning, network configuration
- **Packer**: Talos Linux image templates (optional, can use ISO)
- **Ansible**: Initial Proxmox configuration, ZFS setup

---

### 2.2 Kubernetes OS: Talos Linux

**Decision**: Talos Linux for all Kubernetes nodes

**Rationale**:
- âœ… Immutable, API-only OS (no SSH, minimal attack surface)
- âœ… Kubernetes-optimized
- âœ… Atomic updates with rollback
- âœ… Minimal overhead (~200MB footprint)
- âœ… Native Omni integration

**Versions**:
- Talos: Latest stable (1.9.x)
- Kubernetes: Latest stable (1.32.x)

---

### 2.3 Cluster Management: Omni (Self-Hosted on Oracle Cloud)

**Decision**: Self-hosted Omni on Oracle Cloud ARM instance

**Rationale**:
- âœ… Single pane of glass for all clusters (Dev, Prod, Cloud)
- âœ… Declarative cluster configuration
- âœ… SSO authentication (integrated with Keycloak)
- âœ… Secure kubeconfig distribution
- âœ… Cluster lifecycle management (upgrades, scaling)
- âœ… Multi-cluster visibility
- âœ… Free hosting on Oracle Cloud Always Free tier
- âœ… Accessible from anywhere (no home network exposure)

**Deployment**: Self-Hosted on Oracle Cloud ARM VM (2GB RAM, 1 OCPU)

**Components**:
- **Omni Server**: Main management interface
- **PostgreSQL**: Database for Omni state
- **Nginx**: HTTPS reverse proxy with Let's Encrypt
- **Keycloak Integration**: SSO for all users

**Key Features**:
- **MachineClass**: Define node profiles (control-plane, worker, GPU worker)
- **ClusterTemplate**: Declarative cluster definitions
- **Infrastructure Provider**: Proxmox integration for auto-provisioning

**References**:
- [Deploy Omni On-Prem](https://omni.siderolabs.com/how-to-guides/self_hosted/)
- [Configure Keycloak for Omni](https://docs.siderolabs.com/omni/)

---

### 2.4 GitOps: ArgoCD

**Decision**: ArgoCD for GitOps continuous deployment

**Rationale** (vs Flux):
- âœ… Better UI for multi-cluster management
- âœ… ApplicationSets for dynamic app discovery
- âœ… Sync waves for ordered deployments
- âœ… Web UI for visibility and debugging
- âœ… Strong multi-tenancy support

**Key Features**:
- **Sync Waves**: Ordered deployment (infrastructure â†’ core â†’ apps)
- **ApplicationSets**: Auto-discover apps from directory structure
- **Multi-Cluster**: Deploy to Dev/Prod/Cloud from single ArgoCD
- **Self-Management**: ArgoCD manages its own configuration

**Alternative**: Flux CD (used by Cozystack, also excellent)

---

### 2.5 Dev/Prod Workflow

**Decision**: Separate clusters with promotion pipeline

**Architecture**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Git Push    â”‚â”€â”€â”€â”€â–¶â”‚  CI Pipeline â”‚â”€â”€â”€â”€â–¶â”‚  DEV Deploy  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â–¼
                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                          â”‚  Stability   â”‚
                                          â”‚  Validation  â”‚
                                          â”‚  (24-48h)    â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                  â”‚
                                                  â–¼
                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                          â”‚ PROD Deploy  â”‚
                                          â”‚ (Manual/Auto)â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation**:
```
kubernetes/
â”œâ”€â”€ base/                    # Shared base manifests
â”‚   â””â”€â”€ [service]/
â”œâ”€â”€ overlays/
â”‚   â”œâ”€â”€ dev/                 # Dev-specific patches
â”‚   â”‚   â””â”€â”€ [service]/
â”‚   â””â”€â”€ prod/                # Prod-specific patches
â”‚       â””â”€â”€ [service]/
â””â”€â”€ clusters/
    â”œâ”€â”€ dev/                 # Dev cluster kustomizations
    â”œâ”€â”€ prod/                # Prod cluster kustomizations
    â””â”€â”€ cloud/               # Oracle Cloud cluster
```

**Promotion Strategies**:
1. **Manual**: PR from dev branch to prod branch
2. **Automatic**: Time-based promotion (stable for X hours â†’ auto-promote)
3. **GitOps**: Different branches for dev/prod

---

### 2.6 Networking Architecture

**Decision**: Cilium CNI + Gateway API

**Rationale**:
- âœ… eBPF-based networking (high performance)
- âœ… Gateway API support (modern ingress)
- âœ… Built-in WireGuard encryption
- âœ… Hubble observability
- âœ… Network policies

**Components**:
- **Cilium**: CNI, kube-proxy replacement, network policies
- **MetalLB**: Load balancer for bare metal
- **Gateway API**: Modern ingress (Traefik or Cilium Gateway)
- **external-dns**: Automatic DNS management (Cloudflare)
- **cert-manager**: TLS certificate automation

---

### 2.7 Storage Architecture

**Decision**: Multi-tier storage strategy

**Proxmox (Homelab)**:
```
Storage Tiers:
â”œâ”€â”€ ZFS (local-zfs)          # High-performance, data integrity
â”‚   â”œâ”€â”€ VM disks
â”‚   â””â”€â”€ Container storage
â”œâ”€â”€ Longhorn/OpenEBS         # Kubernetes distributed storage
â”‚   â””â”€â”€ Replicated PVCs
â””â”€â”€ NFS                      # Shared storage for media
    â”œâ”€â”€ Films/Series
    â”œâ”€â”€ Music
    â””â”€â”€ Audiobooks
```

**Oracle Cloud**:
```
Storage Tiers:
â”œâ”€â”€ Block Storage (139GB)    # Boot + ephemeral
â””â”€â”€ NFS via VPN              # Access to homelab storage
```

**Kubernetes Storage Classes**:
- `local-path`: Local node storage (dev, non-critical)
- `longhorn`: Replicated storage (prod, critical)
- `nfs-media`: NFS for media files (12TB)

---

### 2.8 Security Architecture (2-Tier Authentication)

**Authentication Strategy**:

| Tier | Services | Authentication | Rationale |
|------|----------|----------------|-----------|
| **Tier 1 - Private Data** | Nextcloud, Immich, Vaultwarden, BaÃ¯kal, n8n | Keycloak SSO + oauth2-proxy | Sensitive data requires centralized identity |
| **Tier 2 - Media/Public** | Navidrome, Komga, Romm, Audiobookshelf, Mealie, Invidious | App-native auth + Cloudflare | Multi-user apps with built-in user management |

**Security Layers**:
1. **Identity**: Keycloak SSO (OIDC) for private services
2. **Access**: oauth2-proxy for Tier 1, app-native auth for Tier 2
3. **Network**: Cilium network policies, Cloudflare Tunnel (no open ports)
4. **DDoS/WAF**: Cloudflare protection for all public services
5. **Secrets**: External Secrets Operator + Bitwarden (â†’ Vault later)
6. **Images**: Trivy + Grype scanning in CI/CD
7. **OS**: Talos immutable OS (no SSH)

**Secrets Management**:
- **Phase 1**: Bitwarden Secrets (simple, existing infra)
- **Phase 2**: HashiCorp Vault (self-hosted, advanced)

**Zero Trust Architecture**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INTERNET                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                    â”‚                    â”‚
         â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cloudflare      â”‚  â”‚ Twingate        â”‚  â”‚ Keycloak SSO    â”‚
â”‚ Tunnel + WAF    â”‚  â”‚ (Zero Trust)    â”‚  â”‚ + oauth2-proxy  â”‚
â”‚ (All Apps)      â”‚  â”‚ (NFS Access)    â”‚  â”‚ (Tier 1 only)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                    â”‚                    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Oracle Cloud / Homelab       â”‚
              â”‚  (No open ports to internet)  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Benefits**:
- No port forwarding on home router
- Per-service access control (not VPN = full network)
- Cloudflare WAF + DDoS protection for all services
- Keycloak SSO for sensitive data only (reduced complexity)
- Individual user accounts in media apps (playlists, progress tracking)

---

### 2.9 Monitoring & Observability

**Stack**:
- **Metrics**: Prometheus
- **Logs**: Loki + Alloy (Grafana Agent)
- **Dashboards**: Grafana (admin dashboard on Homelab)
- **Alerting**: Alertmanager â†’ ntfy + Telegram â†’ Mobile push
- **User Dashboard**: Glance (Oracle Cloud) for family

**Alerting Flow**:
```
Prometheus â†’ Alertmanager â†’ ntfy (push) + Telegram bot
                              â†“
                         Mobile notifications
```

**Per-Cluster Monitoring**:
- Homelab PROD: Full stack (Prometheus, Grafana, Loki, Alertmanager)
- Oracle Cloud: Lightweight (metrics forwarded to Homelab Grafana)

---

### 2.10 Backup Strategy

**3-2-1 Rule**:
- 3 copies of data
- 2 different storage types
- 1 offsite

**Implementation**:
```
Backup Targets:
â”œâ”€â”€ Local (ZFS snapshots)     # Immediate recovery
â”œâ”€â”€ NAS (rsync/restic)        # Local backup
â””â”€â”€ Cloud (OVH Object Storage) # Offsite (3TB free)
    â”œâ”€â”€ Critical configs
    â”œâ”€â”€ Databases
    â””â”€â”€ Photos (Immich)
```

**Tools**:
- **Velero**: Kubernetes backup (PVs, configs)
- **Restic/Volsync**: File-level backup to S3
- **ZFS snapshots**: Local point-in-time recovery

---

## 3. Cluster Topology

### 3.1 DEV Cluster (Proxmox) - MINIMAL

**Purpose**: Testing, CI validation only (NOT for continuous running)

**Design Philosophy**: 
- Minimal resources - just enough to validate deployments
- Can be shut down when not testing
- Single-node cluster to save resources

**Resources**:
| Node | Role | vCPU | RAM | Storage |
|------|------|------|-----|---------|
| talos-dev | Control Plane + Worker (combined) | 2 | 4GB | 50GB |

**Total**: 2 vCPU, 4GB RAM (can be shut down when not in use)

**Deployed Services**: 
- Same as Prod manifests (validates compatibility)
- Reduced replicas (1 instead of 2+)
- Reduced resource limits via Kustomize overlay
- No persistent data (ephemeral testing only)

---

### 3.2 PROD Cluster (Proxmox)

**Purpose**: Stable production services, local access

**Resources**:
| Node | Role | vCPU | RAM | Storage |
|------|------|------|-----|---------|
| talos-prod-cp | Control Plane | 2 | 4GB | 50GB |
| talos-prod-worker-1 | Worker | 6 | 12GB | 200GB |

**Total**: 8 vCPU, 16GB RAM

**Deployed Services**:
- AdGuard Home (DNS + ad blocking)
- Home Assistant (domotique)
- Komga (comics)
- Romm (ROMs)
- Audiobookshelf (audiobooks)
- Prometheus + Grafana + Loki (monitoring)
- ntfy (push notifications)

**Gaming VM** (Proxmox direct, Phase 3: KubeVirt):
- Windows Gaming VM (32GB RAM, GPU passthrough)
- On-demand streaming style GeForce Now (future)

---

### 3.3 CLOUD Cluster (Oracle Cloud)

**Purpose**: Family-shared services, external access, Omni management

**Resources** (Always Free Tier - 24GB RAM, 4 OCPUs, 200GB storage):
| Node | Role | OCPU | RAM | Storage |
|------|------|------|-----|---------|
| oci-mgmt | Omni + Keycloak + Infra | 1 | 6GB | 50GB |
| oci-node-1 | Control Plane + Worker | 2 | 12GB | 64GB |
| oci-node-2 | Worker | 1 | 6GB | 75GB |

**Total**: 4 OCPUs, 24GB RAM, 189GB storage

**Management Node (oci-mgmt) - NOT in Kubernetes**:
- **Omni** (self-hosted): Talos cluster management
- **Keycloak**: SSO/Identity provider for all services
- **Cloudflare Tunnel**: Zero-trust exposure (no open ports)
- **PostgreSQL**: Database for Omni + Keycloak

**Deployed Services on Kubernetes Cluster**:

**Namespace: media**
- **Comet** (Real-Debrid addon for Stremio clients) âš ï¸ CRITICAL
- Navidrome (music streaming) - storage via NFS to Homelab
- Lidarr (music automation) - storage via NFS to Homelab

> **âš ï¸ COMET CRITICAL REQUIREMENTS**:
> - **Static IP**: Real-Debrid requires consistent IP (bans accounts for IP changes)
> - **Maximum Uptime**: Family depends on this for streaming
> - **Oracle Cloud Fit**: Static public IP + enterprise uptime + Always Free
> - Stremio is a desktop/mobile client - users install locally and connect to Comet

**Namespace: critical** (Keycloak SSO)
- Vaultwarden (passwords)
- BaÃ¯kal (CalDAV/CardDAV)
- Twingate Connector (Zero Trust VPN to homelab for NFS)
- oauth2-proxy (SSO enforcement)

**Namespace: collaborative** (Keycloak SSO)
- Nextcloud (cloud storage) - storage via NFS to Homelab

**Namespace: dashboard**
- Glance (family dashboard/homepage)

**Namespace: optional** (Phase 2 - deploy as resources allow)
- Immich (photos) - Keycloak SSO, storage via NFS to Homelab
- n8n (automation workflows) - Keycloak SSO
- Mealie (recipes) - app-native auth
- Invidious (YouTube frontend) - app-native auth

---

## 4. Implementation Patterns

### 4.1 Repository Structure

```
homelab/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml                    # Lint, validate, security scan
â”‚       â”œâ”€â”€ deploy-dev.yml            # Deploy to DEV on push
â”‚       â”œâ”€â”€ promote-prod.yml          # Promote DEV â†’ PROD
â”‚       â”œâ”€â”€ renovate.yml              # Dependency updates
â”‚       â””â”€â”€ trivy-scan.yml            # Image security scanning
â”‚
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ proxmox/
â”‚   â”‚   â”œâ”€â”€ main.tf                   # Provider configuration
â”‚   â”‚   â”œâ”€â”€ variables.tf              # Input variables
â”‚   â”‚   â”œâ”€â”€ outputs.tf                # Output values
â”‚   â”‚   â”œâ”€â”€ talos-vms.tf              # Talos VM definitions
â”‚   â”‚   â”œâ”€â”€ gaming-vms.tf             # Gaming VM definitions
â”‚   â”‚   â””â”€â”€ network.tf                # Network configuration
â”‚   â””â”€â”€ oracle-cloud/
â”‚       â”œâ”€â”€ main.tf                   # OCI provider
â”‚       â”œâ”€â”€ compute.tf                # VM instances (mgmt + k8s nodes)
â”‚       â””â”€â”€ network.tf                # VCN, subnets
â”‚
â”œâ”€â”€ docker/                            # Docker Compose for management VM
â”‚   â””â”€â”€ oci-mgmt/
â”‚       â”œâ”€â”€ docker-compose.yml        # Omni + Keycloak + Cloudflare
â”‚       â”œâ”€â”€ omni/
â”‚       â”‚   â””â”€â”€ config.yaml           # Omni configuration
â”‚       â”œâ”€â”€ keycloak/
â”‚       â”‚   â””â”€â”€ realm-export.json     # Keycloak realm config
â”‚       â”œâ”€â”€ cloudflared/
â”‚       â”‚   â””â”€â”€ config.yml            # Tunnel configuration
â”‚       â””â”€â”€ nginx/
â”‚           â””â”€â”€ nginx.conf            # Reverse proxy config
â”‚
â”œâ”€â”€ omni/
â”‚   â”œâ”€â”€ clusters/
â”‚   â”‚   â”œâ”€â”€ dev.yaml                  # DEV cluster template
â”‚   â”‚   â”œâ”€â”€ prod.yaml                 # PROD cluster template
â”‚   â”‚   â””â”€â”€ cloud.yaml                # CLOUD cluster template
â”‚   â”œâ”€â”€ machine-classes/
â”‚   â”‚   â”œâ”€â”€ control-plane.yaml        # CP machine class
â”‚   â”‚   â”œâ”€â”€ worker.yaml               # Standard worker
â”‚   â”‚   â””â”€â”€ gpu-worker.yaml           # GPU-enabled worker
â”‚   â””â”€â”€ patches/
â”‚       â””â”€â”€ cilium-config.yaml        # Cilium configuration
â”‚
â”œâ”€â”€ kubernetes/
â”‚   â”œâ”€â”€ base/                         # Base manifests (shared)
â”‚   â”‚   â”œâ”€â”€ argocd/                   # ArgoCD configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ install.yaml          # ArgoCD installation
â”‚   â”‚   â”‚   â”œâ”€â”€ root.yaml             # Root application
â”‚   â”‚   â”‚   â””â”€â”€ apps/                 # ApplicationSets
â”‚   â”‚   â”‚       â”œâ”€â”€ infra.yaml        # Infrastructure apps (wave 0-1)
â”‚   â”‚   â”‚       â”œâ”€â”€ core.yaml         # Core services (wave 2)
â”‚   â”‚   â”‚       â”œâ”€â”€ monitoring.yaml   # Monitoring (wave 3)
â”‚   â”‚   â”‚       â””â”€â”€ apps.yaml         # User applications (wave 4)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ infrastructure/           # Wave 0-1
â”‚   â”‚   â”‚   â”œâ”€â”€ cilium/
â”‚   â”‚   â”‚   â”œâ”€â”€ metallb/
â”‚   â”‚   â”‚   â”œâ”€â”€ cert-manager/
â”‚   â”‚   â”‚   â”œâ”€â”€ external-dns/
â”‚   â”‚   â”‚   â”œâ”€â”€ external-secrets/
â”‚   â”‚   â”‚   â”œâ”€â”€ longhorn/             # Prod storage
â”‚   â”‚   â”‚   â””â”€â”€ local-path/           # Dev storage (minimal)
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ security/                 # Wave 2
â”‚   â”‚   â”‚   â”œâ”€â”€ oauth2-proxy/         # SSO enforcement (Tier 1)
â”‚   â”‚   â”‚   â”œâ”€â”€ twingate/             # Zero Trust connector
â”‚   â”‚   â”‚   â”œâ”€â”€ vaultwarden/
â”‚   â”‚   â”‚   â””â”€â”€ baikal/
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ monitoring/               # Wave 3
â”‚   â”‚   â”‚   â”œâ”€â”€ prometheus/
â”‚   â”‚   â”‚   â”œâ”€â”€ grafana/
â”‚   â”‚   â”‚   â”œâ”€â”€ loki/
â”‚   â”‚   â”‚   â”œâ”€â”€ alloy/                # Grafana agent
â”‚   â”‚   â”‚   â”œâ”€â”€ alertmanager/
â”‚   â”‚   â”‚   â””â”€â”€ ntfy/                 # Push notifications
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ apps/                     # Wave 4
â”‚   â”‚       â”œâ”€â”€ media/
â”‚   â”‚       â”‚   â”œâ”€â”€ comet/            # Real-Debrid addon (CRITICAL)
â”‚   â”‚       â”‚   â”œâ”€â”€ navidrome/        # Oracle Cloud
â”‚   â”‚       â”‚   â””â”€â”€ lidarr/           # Oracle Cloud
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ home/                 # Homelab PROD only
â”‚   â”‚       â”‚   â”œâ”€â”€ adguard-home/     # DNS + ad blocking
â”‚   â”‚       â”‚   â”œâ”€â”€ home-assistant/
â”‚   â”‚       â”‚   â”œâ”€â”€ audiobookshelf/   # Moved from Cloud
â”‚   â”‚       â”‚   â”œâ”€â”€ komga/
â”‚   â”‚       â”‚   â””â”€â”€ romm/
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ collaborative/
â”‚   â”‚       â”‚   â””â”€â”€ nextcloud/
â”‚   â”‚       â”‚
â”‚   â”‚       â”œâ”€â”€ dashboard/
â”‚   â”‚       â”‚   â””â”€â”€ glance/           # Family dashboard
â”‚   â”‚       â”‚
â”‚   â”‚       â””â”€â”€ optional/             # Phase 2
â”‚   â”‚           â”œâ”€â”€ immich/
â”‚   â”‚           â”œâ”€â”€ n8n/
â”‚   â”‚           â”œâ”€â”€ mealie/
â”‚   â”‚           â””â”€â”€ invidious/
â”‚   â”‚
â”‚   â”œâ”€â”€ overlays/
â”‚   â”‚   â”œâ”€â”€ dev/                      # DEV-specific patches
â”‚   â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”‚   â”‚   â””â”€â”€ patches/
â”‚   â”‚   â”œâ”€â”€ prod/                     # PROD-specific patches
â”‚   â”‚   â”‚   â”œâ”€â”€ kustomization.yaml
â”‚   â”‚   â”‚   â””â”€â”€ patches/
â”‚   â”‚   â””â”€â”€ cloud/                    # Oracle Cloud patches
â”‚   â”‚       â”œâ”€â”€ kustomization.yaml
â”‚   â”‚       â””â”€â”€ patches/
â”‚   â”‚
â”‚   â””â”€â”€ clusters/                     # Per-cluster configs
â”‚       â”œâ”€â”€ dev/
â”‚       â”‚   â””â”€â”€ kustomization.yaml    # Points to base + dev overlay
â”‚       â”œâ”€â”€ prod/
â”‚       â”‚   â””â”€â”€ kustomization.yaml    # Points to base + prod overlay
â”‚       â””â”€â”€ cloud/
â”‚           â””â”€â”€ kustomization.yaml    # Points to base + cloud overlay
â”‚
â”œâ”€â”€ ansible/
â”‚   â”œâ”€â”€ playbooks/
â”‚   â”‚   â”œâ”€â”€ proxmox-setup.yml         # Initial Proxmox config
â”‚   â”‚   â”œâ”€â”€ zfs-setup.yml             # ZFS pool configuration
â”‚   â”‚   â””â”€â”€ security-hardening.yml    # Security baseline
â”‚   â””â”€â”€ inventory/
â”‚       â””â”€â”€ hosts.yml
â”‚
â”œâ”€â”€ packer/                            # VM template building
â”‚   â””â”€â”€ talos/
â”‚       â”œâ”€â”€ talos.pkr.hcl             # Talos image template
â”‚       â””â”€â”€ variables.pkr.hcl
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ bootstrap-cluster.sh          # Initial cluster bootstrap
â”‚   â”œâ”€â”€ promote-to-prod.sh            # DEV â†’ PROD promotion
â”‚   â”œâ”€â”€ backup.sh                     # Backup automation
â”‚   â””â”€â”€ validate-manifests.sh         # Pre-commit validation
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ installation.md
â”‚   â”œâ”€â”€ operations.md
â”‚   â”œâ”€â”€ troubleshooting.md
â”‚   â””â”€â”€ runbooks/
â”‚
â”œâ”€â”€ .taskfiles/                        # Taskfile definitions
â”‚   â”œâ”€â”€ Taskfile.terraform.yml
â”‚   â”œâ”€â”€ Taskfile.kubernetes.yml
â”‚   â””â”€â”€ Taskfile.backup.yml
â”‚
â”œâ”€â”€ Taskfile.yaml                      # Main taskfile
â”œâ”€â”€ renovate.json                      # Renovate configuration
â”œâ”€â”€ .sops.yaml                         # SOPS encryption config
â””â”€â”€ README.md
```

---

### 4.2 ArgoCD Sync Waves

**Wave Architecture** (inspired by mitchross/talos-argocd-proxmox):

```yaml
# Wave 0: Foundation (Networking & Secrets)
- Cilium
- MetalLB
- External Secrets Operator
- cert-manager

# Wave 1: Storage
- Longhorn / OpenEBS
- NFS provisioner

# Wave 2: Core Infrastructure
- external-dns
- Traefik / Gateway API
- Databases (PostgreSQL, Redis)

# Wave 3: Monitoring
- Prometheus
- Grafana
- Loki
- Alertmanager

# Wave 4: Applications
- User workloads
- Media services
- Collaborative tools
```

**Implementation**:
```yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: cilium
  annotations:
    argocd.argoproj.io/sync-wave: "0"
spec:
  # ...
```

---

### 4.3 Service Pattern Template

**Standard service structure**:
```
kubernetes/base/apps/[category]/[service-name]/
â”œâ”€â”€ deployment.yaml           # Deployment resource
â”œâ”€â”€ service.yaml              # Service resource
â”œâ”€â”€ configmap.yaml            # Non-sensitive config
â”œâ”€â”€ external-secret.yaml      # Secrets from Vault/Bitwarden
â”œâ”€â”€ pvc.yaml                  # Persistent storage
â”œâ”€â”€ ingress.yaml              # Ingress/HTTPRoute
â”œâ”€â”€ network-policy.yaml       # Network isolation
â”œâ”€â”€ servicemonitor.yaml       # Prometheus metrics
â””â”€â”€ kustomization.yaml        # Kustomize file
```

**Naming Conventions**:
- **Deployment**: `[service-name]`
- **Service**: `[service-name]`
- **ConfigMap**: `[service-name]-config`
- **Secret**: `[service-name]-secrets`
- **PVC**: `[service-name]-data`
- **Ingress**: `[service-name]`

**Mandatory Labels**:
```yaml
labels:
  app.kubernetes.io/name: [service-name]
  app.kubernetes.io/instance: [service-name]
  app.kubernetes.io/component: [component]
  app.kubernetes.io/part-of: homelab
  app.kubernetes.io/managed-by: argocd
```

---

### 4.4 Environment Overlays

**Base â†’ Overlay Pattern**:

```yaml
# kubernetes/overlays/dev/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
namespace: default
resources:
  - ../../base/apps/media/navidrome
patches:
  - patch: |
      - op: replace
        path: /spec/replicas
        value: 1
    target:
      kind: Deployment
      name: navidrome
  - path: patches/resources-dev.yaml
```

```yaml
# kubernetes/overlays/prod/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
namespace: default
resources:
  - ../../base/apps/media/navidrome
patches:
  - path: patches/resources-prod.yaml
  - path: patches/replicas-prod.yaml
```

---

### 4.5 Terraform Patterns for Proxmox

**Talos VM Definition**:
```hcl
# terraform/proxmox/talos-vms.tf
resource "proxmox_virtual_environment_vm" "talos_prod_cp" {
  name      = "talos-prod-cp"
  node_name = "proxmox"
  
  cpu {
    cores = 2
    type  = "host"
  }
  
  memory {
    dedicated = 4096
  }
  
  disk {
    datastore_id = "local-zfs"
    file_id      = proxmox_virtual_environment_download_file.talos_iso.id
    interface    = "virtio0"
    size         = 50
  }
  
  network_device {
    bridge = "vmbr0"
  }
  
  operating_system {
    type = "l26"  # Linux 2.6+ kernel
  }
  
  tags = ["talos", "kubernetes", "prod", "control-plane"]
}
```

---

### 4.6 Omni Cluster Templates

**Cluster Definition** (inspired by qjoly/GitOps):
```yaml
# omni/clusters/prod.yaml
kind: Cluster
metadata:
  name: prod
  labels:
    environment: production
spec:
  talosVersion: 1.9.0
  kubernetesVersion: 1.32.0
  
  controlPlane:
    machineClass: control-plane
    replicas: 1
    patches:
      - |
        machine:
          network:
            hostname: talos-prod-cp
          install:
            disk: /dev/vda
            
  workers:
    - machineClass: worker
      replicas: 1
      patches:
        - |
          machine:
            network:
              hostname: talos-prod-worker-1
              
    - machineClass: gpu-worker
      replicas: 1
      patches:
        - |
          machine:
            network:
              hostname: talos-prod-gpu
          kubelet:
            extraArgs:
              feature-gates: DevicePlugins=true
```

---

## 5. Services Catalog

### 5.0 Management Services (Oracle Cloud - NOT in K8s)

| Service | RAM | Description | Priority | Source |
|---------|-----|-------------|----------|--------|
| **Omni** | 1GB | Talos cluster management | ðŸ”´ Critical | Sidero Labs |
| **Keycloak** | 1GB | SSO/Identity provider (OIDC) | ðŸ”´ Critical | [Various repos] |
| **PostgreSQL** | 512MB | Database for Omni + Keycloak | ðŸ”´ Critical | - |
| **Cloudflare Tunnel** | 128MB | Zero-trust ingress (no open ports) | ðŸ”´ Critical | [qjoly, Mafyuh] |
| **Nginx** | 128MB | Reverse proxy + TLS termination | ðŸ”´ Critical | - |

**Total**: ~3GB RAM (runs on oci-mgmt VM, separate from K8s cluster)

**Why Keycloak?** (inspired by multiple homelab repos):
- Single Sign-On for all services (Grafana, ArgoCD, Nextcloud, etc.)
- OIDC/SAML support
- User federation and role management
- Family member access control
- Integrates with Omni for cluster access

---

### 5.1 Media Services (Oracle Cloud K8s)

| Service | RAM | Description | Priority | Auth | Storage |
|---------|-----|-------------|----------|------|---------|
| **Comet** | 256MB | Real-Debrid addon for Stremio | ðŸ”´ Critical | - | - |
| **Navidrome** | 512MB | Music streaming (Subsonic compatible) | ðŸ”´ Critical | App-native | NFS â†’ Homelab |
| **Lidarr** | 512MB | Music library automation | ðŸŸ¡ Important | App-native | NFS â†’ Homelab |

**Total**: ~1.3GB RAM

> **Stremio**: NOT hosted - it's a client app users install on their devices
> **Audiobookshelf**: Moved to Homelab PROD (local access, no need for cloud)

---

### 5.2 Critical Services (Oracle Cloud K8s)

| Service | RAM | Description | Priority | Auth |
|---------|-----|-------------|----------|------|
| **Vaultwarden** | 256MB | Password manager | ðŸ”´ Critical | Keycloak SSO |
| **BaÃ¯kal** | 256MB | CalDAV/CardDAV | ðŸ”´ Critical | Keycloak SSO |
| **Twingate Connector** | 128MB | Zero Trust VPN to homelab (NFS) | ðŸ”´ Critical | - |
| **oauth2-proxy** | 128MB | SSO enforcement for Tier 1 services | ðŸ”´ Critical | - |

**Total**: ~768MB RAM

**Why Twingate over WireGuard?**:
- Zero Trust architecture (no open ports on homelab)
- Per-service access control (not full network access)
- Works through NAT without port forwarding
- Free tier: 5 users (perfect for family)
- Used for NFS access from Oracle Cloud to Homelab storage

---

### 5.3 Collaborative Services (Oracle Cloud K8s)

| Service | RAM | Description | Priority | Auth | Storage |
|---------|-----|-------------|----------|------|---------|
| **Nextcloud** | 2GB | Cloud storage + collaboration | ðŸ”´ Critical | Keycloak SSO | NFS â†’ Homelab |

**Total**: ~2GB RAM

> **Removed**: Gitea (GitHub sufficient), Actual Budget, La Suite (not needed)

---

### 5.4 Optional/Automation Services (Oracle Cloud K8s) - Phase 2

| Service | RAM | Description | Priority | Auth | Storage |
|---------|-----|-------------|----------|------|---------|
| **Glance** | 256MB | Family dashboard/homepage | ðŸŸ¡ Important | App-native | - |
| **Immich** | 2GB | Photo management | ðŸŸ¢ Phase 2 | Keycloak SSO | NFS â†’ Homelab |
| **n8n** | 512MB | Workflow automation | ðŸŸ¢ Phase 2 | Keycloak SSO | - |
| **Mealie** | 512MB | Recipe management | ðŸŸ¢ Phase 2 | App-native | - |
| **Invidious** | 1GB | YouTube frontend (privacy) | ðŸŸ¢ Phase 2 | App-native | - |

**Total**: ~4.3GB RAM (deploy after MVP when infra is stable)

**Why n8n?**:
- Automate workflows between services
- Self-hosted alternative to Zapier/Make
- Integrates with 400+ apps
- Useful for: backup notifications, service health checks, family alerts

---

### 5.5 Home Services (Homelab PROD)

| Service | RAM | Description | Priority | Auth |
|---------|-----|-------------|----------|------|
| **AdGuard Home** | 256MB | DNS + ad blocking (DoH/DoT native) | ðŸ”´ Critical | Local |
| **Home Assistant** | 2GB | Home automation | ðŸ”´ Critical | Local |
| **Audiobookshelf** | 1GB | Audiobook management/streaming | ðŸŸ¡ Important | App-native |
| **Komga** | 2GB | Comics/manga server | ðŸŸ¡ Important | App-native |
| **Romm** | 1GB | ROM management | ðŸŸ¡ Important | App-native |

**Total**: ~6.3GB RAM

> **Removed**: Pi-hole (replaced by AdGuard Home), Uptime Kuma (Alertmanager sufficient), Frigate (deferred), Homaar (Glance on Oracle Cloud)
> **Why AdGuard Home over Pi-hole?**: Modern UI, native DoH/DoT, lighter RAM, simpler config

---

### 5.6 Monitoring (Homelab PROD)

| Service | RAM | Description | Priority |
|---------|-----|-------------|----------|
| **Prometheus** | 1GB | Metrics collection | ðŸ”´ Critical |
| **Grafana** | 512MB | Admin dashboards & visualization | ðŸ”´ Critical |
| **Loki** | 512MB | Log aggregation | ðŸŸ¡ Important |
| **Alertmanager** | 256MB | Alert routing to ntfy + Telegram | ðŸŸ¡ Important |
| **Alloy** | 256MB | Grafana agent for logs/metrics | ðŸŸ¡ Important |
| **ntfy** | 128MB | Push notifications | ðŸŸ¡ Important |

**Total**: ~2.7GB RAM

**Alerting Channels**:
- **ntfy**: Mobile push notifications (self-hosted)
- **Telegram**: Bot for critical alerts

> **Removed**: Wazuh SIEM (overkill for homelab - Talos immutable OS + Cloudflare + Keycloak provide sufficient security)

---

### 5.7 CI/CD Security Tools (GitHub Actions)

| Service | RAM | Location | Description | Source |
|---------|-----|----------|-------------|--------|
| **Trivy** | - | CI/CD | Image & config scanning | [Mafyuh] |
| **Grype** | - | CI/CD | Vulnerability scanning | [Mafyuh] |
| **GitGuardian** | - | CI/CD | Secret detection | [Mafyuh] |
| **kubeval** | - | CI/CD | Kubernetes manifest validation | [mitchross] |
| **yamllint** | - | CI/CD | YAML linting | - |

> These run in GitHub Actions, not on cluster resources

---

### 5.8 Gaming (Homelab)

**MVP (Proxmox Direct)**:
| VM | RAM | vCPU | GPU | Storage |
|----|-----|------|-----|---------|
| **Windows Gaming** | 32GB | 8 | Yes (passthrough) | 1TB |

**Phase 3 (KubeVirt - Future)**:
- On-demand VM provisioning via Kubernetes API
- Game streaming style GeForce Now
- VM templates for instant startup
- Web interface to launch gaming sessions

> **Removed**: Linux VM (not needed)
> **Gaming VM is OFF most of the time** - only started for gaming sessions

---

## 6. CI/CD Pipeline

### 6.1 Workflow Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Git Push   â”‚â”€â”€â”€â–¶â”‚  CI Pipeline â”‚â”€â”€â”€â–¶â”‚  Deploy DEV  â”‚â”€â”€â”€â–¶â”‚  Stability   â”‚
â”‚   (main)     â”‚    â”‚  (Validate)  â”‚    â”‚  (Auto)      â”‚    â”‚  Validation  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                    â”‚
                                                                    â–¼
                                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                            â”‚  Promote to  â”‚
                                                            â”‚  PROD (Manualâ”‚
                                                            â”‚  or Auto)    â”‚
                                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 GitHub Actions Workflows

**CI Pipeline** (`.github/workflows/ci.yml`):
```yaml
name: CI
on: [push, pull_request]

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Validate Kubernetes manifests
        uses: instrumenta/kubeval-action@master
        
      - name: Lint YAML
        uses: ibiqlik/action-yamllint@v3
        
      - name: Security scan with Trivy
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'config'
          scan-ref: 'kubernetes/'
```

**Deploy to DEV** (`.github/workflows/deploy-dev.yml`):
```yaml
name: Deploy to DEV
on:
  push:
    branches: [main]
    paths:
      - 'kubernetes/**'

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure kubectl
        run: |
          echo "${{ secrets.DEV_KUBECONFIG }}" | base64 -d > kubeconfig
          
      - name: Sync ArgoCD Applications
        run: |
          argocd app sync --prune --server $ARGOCD_SERVER
```

**Promote to PROD** (`.github/workflows/promote-prod.yml`):
```yaml
name: Promote to PROD
on:
  workflow_dispatch:  # Manual trigger
  schedule:
    - cron: '0 6 * * 1'  # Weekly Monday 6 AM (optional auto)

jobs:
  promote:
    runs-on: ubuntu-latest
    steps:
      - name: Check DEV stability
        run: |
          # Query Prometheus for error rates, alerts, etc.
          
      - name: Deploy to PROD
        if: success()
        run: |
          argocd app sync --prune --server $ARGOCD_SERVER
```

---

## 7. Renovate Configuration

**Automated dependency updates** (inspired by ahinko/home-ops):

```json5
// renovate.json
{
  "$schema": "https://docs.renovatebot.com/renovate-schema.json",
  "extends": [
    "config:recommended",
    "docker:enableMajor",
    ":semanticCommits",
    ":automergeDigest",
    ":automergeBranch"
  ],
  "kubernetes": {
    "fileMatch": ["kubernetes/.+\\.ya?ml$"]
  },
  "helm-values": {
    "fileMatch": ["kubernetes/.+\\.ya?ml$"]
  },
  "packageRules": [
    {
      "description": "Auto-merge minor/patch for trusted packages",
      "matchUpdateTypes": ["minor", "patch"],
      "matchPackageNames": ["ghcr.io/linuxserver/*"],
      "automerge": true
    },
    {
      "description": "Group Prometheus stack updates",
      "matchPackagePatterns": ["prometheus", "grafana", "alertmanager"],
      "groupName": "monitoring-stack"
    }
  ]
}
```

---

## 8. Resource Allocation Summary

### Homelab (64GB RAM)

| Component | RAM | Notes |
|-----------|-----|-------|
| **Proxmox Host** | 4GB | OS overhead |
| **ZFS ARC Cache** | 8GB | Performance |
| **DEV Cluster** | 4GB | Minimal testing (can be stopped) |
| **PROD Cluster** | 16GB | Production services |
| **Gaming VM** | 32GB | When active (OFF most of the time) |
| **Reserve** | 4GB | Buffer |

**PROD Cluster Breakdown** (~16GB):
| Service | RAM |
|---------|-----|
| K8s overhead | 2GB |
| AdGuard Home | 256MB |
| Home Assistant | 2GB |
| Audiobookshelf | 1GB |
| Komga | 2GB |
| Romm | 1GB |
| Prometheus | 1GB |
| Grafana | 512MB |
| Loki | 512MB |
| Alertmanager | 256MB |
| Alloy | 256MB |
| ntfy | 128MB |
| Reserve | ~5GB |

**Normal Operation**: ~28GB used (PROD active, DEV stopped, Gaming OFF)
**Testing Mode**: ~32GB used (DEV + PROD, Gaming OFF)
**Gaming Mode**: ~48GB used (Gaming VM + PROD, DEV stopped)

---

### Oracle Cloud (24GB RAM, 4 OCPUs)

**Management VM (oci-mgmt)** - Docker, NOT Kubernetes:
| Component | RAM | Notes |
|-----------|-----|-------|
| **Omni** | 1GB | Cluster management |
| **Keycloak** | 1GB | SSO/Identity |
| **PostgreSQL** | 512MB | Database |
| **Cloudflare Tunnel** | 128MB | Zero-trust ingress |
| **Nginx** | 128MB | Reverse proxy |
| **Reserve** | 2GB | Buffer |
| **Total** | **~5GB** | 1 OCPU |

**Kubernetes Cluster (oci-node-1 + oci-node-2)** - MVP:
| Component | RAM | Notes |
|-----------|-----|-------|
| **K8s Overhead** | 2GB | Control plane, Cilium |
| **Media Services** | 1.3GB | Comet, Navidrome, Lidarr |
| **Critical Services** | 0.8GB | Vaultwarden, BaÃ¯kal, Twingate, oauth2-proxy |
| **Collaborative** | 2GB | Nextcloud |
| **Dashboard** | 256MB | Glance |
| **Reserve** | ~6GB | Buffer for Phase 2 services |
| **Total MVP** | **~12GB** | 3 OCPUs |

**Phase 2 Addition**:
| Component | RAM | Notes |
|-----------|-----|-------|
| **Immich** | 2GB | Photos |
| **n8n** | 512MB | Automation |
| **Mealie** | 512MB | Recipes |
| **Invidious** | 1GB | YouTube |
| **Total Phase 2** | **~4GB** | |

**Grand Total**: ~16-19GB RAM, 4 OCPUs âœ… Within Always Free limits

---

## 9. Implementation Roadmap

### Phase 1: Foundation
- [ ] Terraform Proxmox VMs (DEV + PROD nodes)
- [ ] Omni setup on Oracle Cloud (self-hosted)
- [ ] DEV cluster bootstrap (Talos + Kubernetes)
- [ ] ArgoCD installation
- [ ] Cilium CNI deployment

### Phase 2: Core Infrastructure
- [ ] Storage (Longhorn/OpenEBS)
- [ ] cert-manager + external-dns
- [ ] External Secrets Operator + Bitwarden
- [ ] Monitoring stack (Prometheus, Grafana, Loki, ntfy)
- [ ] AdGuard Home (DNS)

### Phase 3: PROD Cluster + Oracle Cloud
- [ ] PROD cluster bootstrap
- [ ] Terraform OCI instances
- [ ] Oracle Cloud K8s cluster
- [ ] Keycloak SSO + Cloudflare Tunnel
- [ ] Twingate connector for NFS access
- [ ] CI/CD pipeline setup

### Phase 4: Services MVP
- [ ] Critical: Vaultwarden, BaÃ¯kal
- [ ] Collaborative: Nextcloud
- [ ] Media: Comet, Navidrome, Lidarr
- [ ] Home: Home Assistant, Komga, Romm, Audiobookshelf
- [ ] Dashboard: Glance (family), Grafana (admin)

### Phase 5: Optional Services
- [ ] Immich (photos)
- [ ] n8n (automation)
- [ ] Mealie (recipes)
- [ ] Invidious (YouTube)

### Phase 6: Gaming & Advanced
- [ ] GPU passthrough setup
- [ ] Windows Gaming VM (Proxmox direct)
- [ ] KubeVirt integration (on-demand gaming)
- [ ] Backup automation

---

## 10. Validation Checklist

### Pre-Deployment
- [ ] All manifests pass `kubeval`
- [ ] No secrets in Git (checked by GitGuardian)
- [ ] Trivy scan passes (no critical vulnerabilities)
- [ ] YAML lint passes

### Post-Deployment
- [ ] All pods Running/Ready
- [ ] Ingress accessible
- [ ] TLS certificates valid
- [ ] Prometheus scraping metrics
- [ ] Alertmanager configured

---

**Document Status**: âœ… **VALIDATED & READY FOR IMPLEMENTATION**

Architecture v4.0 validated on 2026-01-29. Key changes from v3.1:
- Simplified service catalog (removed 12 services)
- 2-tier authentication strategy (Keycloak SSO for private, app-native for media)
- AdGuard Home replaces Pi-hole
- Audiobookshelf moved to Homelab
- ntfy + Telegram for alerting (removed Wazuh, Uptime Kuma)
- KubeVirt gaming roadmap (Phase 6)

This design provides:
- Clear separation of Dev/Prod environments
- GitOps-native CI/CD workflow
- Hybrid cloud architecture (Homelab + Oracle Cloud)
- Optimized service catalog with clear priorities
- Scalable, maintainable structure
- Reduced complexity and resource usage

Begin with Phase 1: Terraform Proxmox VMs and Omni setup.
